{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb174e09",
   "metadata": {},
   "source": [
    "# 1. Imports & Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c05d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "Transformers version: 4.50.3\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from transformers import ViTMAEModel, get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "import transformers\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6ee66",
   "metadata": {},
   "source": [
    "# 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd059362",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(r\"D:\\Swinburne\\Degree3_S2\\COS30082_AML\\GroupAssignment\\dataset\")\n",
    "list_dir  = data_root / \"list\"\n",
    "\n",
    "class Config:\n",
    "    data_root = data_root\n",
    "    list_dir  = list_dir\n",
    "    \n",
    "    train_list_path = list_dir / \"train.txt\"\n",
    "    test_list_path  = list_dir / \"test.txt\"\n",
    "    gt_list_path    = list_dir / \"groundtruth.txt\"\n",
    "\n",
    "    model_name = \"facebook/vit-mae-large\"\n",
    "    num_classes = 100\n",
    "\n",
    "    img_size   = 224\n",
    "    batch_size = 16\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "    persistent_workers = False\n",
    "\n",
    "    epochs        = 30\n",
    "    lr            = 5e-5\n",
    "    weight_decay  = 0.05\n",
    "    \n",
    "    # lr            = 1e-3\n",
    "    # weight_decay  = 1e-4\n",
    "    warmup_ratio  = 0.1\n",
    "\n",
    "    seed = 42\n",
    "    # out_dir = Path(\"./test\")\n",
    "    out_dir = Path(\"./runs_mae_large_AUG_5e-5\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474028d",
   "metadata": {},
   "source": [
    "# 3. Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4815f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f5967",
   "metadata": {},
   "source": [
    "# 4. Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac36d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_AUG = True\n",
    "\n",
    "# ===============================\n",
    "# Define all transforms\n",
    "# ===============================\n",
    "\n",
    "IMAGE_SIZE = 224  # 如果你文件里是别的，请同步修改\n",
    "\n",
    "# Herbarium heavy augmentation\n",
    "train_herbarium_transform = T.Compose([\n",
    "    T.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
    "    T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.RandomRotation(45),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Photo light augmentation\n",
    "train_photo_transform = T.Compose([\n",
    "    T.RandomResizedCrop(IMAGE_SIZE),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Validation/Test: no augmentation\n",
    "eval_transform = T.Compose([\n",
    "    T.Resize(IMAGE_SIZE + 32),\n",
    "    T.CenterCrop(IMAGE_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ===============================\n",
    "# Unified transform selector\n",
    "# ===============================\n",
    "def pick_transform(rel_path: str, train: bool = True):\n",
    "    \"\"\"\n",
    "    Automatically pick transform based on folder name.\n",
    "    rel_path: dataset path (string), used to detect 'herbarium' or 'photo'.\n",
    "    train: if False → always use eval_transform\n",
    "    \"\"\"\n",
    "    low = rel_path.lower()\n",
    "\n",
    "    # -----------------------\n",
    "    # Validation/test mode: never augment\n",
    "    # -----------------------\n",
    "    if not train:\n",
    "        return eval_transform\n",
    "\n",
    "    # -----------------------\n",
    "    # Training but augmentation disabled\n",
    "    # -----------------------\n",
    "    if not USE_AUG:\n",
    "        return eval_transform\n",
    "\n",
    "    # -----------------------\n",
    "    # Training with augmentation enabled\n",
    "    # -----------------------\n",
    "    if \"herbarium\" in low:\n",
    "        return train_herbarium_transform\n",
    "\n",
    "    if \"photo\" in low:\n",
    "        return train_photo_transform\n",
    "\n",
    "    # Default → treat as Photo dataset\n",
    "    return train_photo_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e063e48",
   "metadata": {},
   "source": [
    "# 5. Loading train/test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec53634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Path Check ===\n",
      "D:\\Swinburne\\Degree3_S2\\COS30082_AML\\GroupAssignment\\dataset -> True\n",
      "D:\\Swinburne\\Degree3_S2\\COS30082_AML\\GroupAssignment\\dataset\\list\\train.txt -> True\n",
      "D:\\Swinburne\\Degree3_S2\\COS30082_AML\\GroupAssignment\\dataset\\list\\test.txt -> True\n",
      "D:\\Swinburne\\Degree3_S2\\COS30082_AML\\GroupAssignment\\dataset\\list\\groundtruth.txt -> True\n",
      "Line counts -> train=4744, test=207, groundtruth=207\n",
      "[Info] Original label min=12254, max=285398\n",
      "[Info] Number of unique labels=100\n",
      "[Info] Train samples: 4744, Val samples: 207, Unmatched test: 0\n",
      "[Info] Labels have been remapped to range [0, 99]\n"
     ]
    }
   ],
   "source": [
    "def read_groundtruth(gt_path: Path):\n",
    "    mapping = {}\n",
    "    with open(gt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                mapping[parts[0]] = int(parts[-1])\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def read_train_list(list_path: Path):\n",
    "    \"\"\"Expect: train.txt lines are '<rel_path> <label>'\"\"\"\n",
    "    samples = []\n",
    "    with open(list_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2:\n",
    "                raise ValueError(f\"Train line has no label: {line}\")\n",
    "            rel_path = parts[0]\n",
    "            label = int(parts[1])\n",
    "            samples.append((rel_path, label))\n",
    "    return samples\n",
    "\n",
    "\n",
    "def read_test_list(list_path: Path):\n",
    "    \"\"\"Expect: test.txt lines are either '<rel_path>' or '<rel_path> <label>'\"\"\"\n",
    "    samples = []\n",
    "    with open(list_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if not parts:\n",
    "                continue\n",
    "            rel_path = parts[0]\n",
    "            label = int(parts[1]) if len(parts) >= 2 else None\n",
    "            samples.append((rel_path, label))\n",
    "    return samples\n",
    "\n",
    "\n",
    "print(\"=== Path Check ===\")\n",
    "print(f\"{Config.data_root} -> {Config.data_root.exists()}\")\n",
    "print(f\"{Config.train_list_path} -> {Config.train_list_path.exists()}\")\n",
    "print(f\"{Config.test_list_path} -> {Config.test_list_path.exists()}\")\n",
    "print(f\"{Config.gt_list_path} -> {Config.gt_list_path.exists()}\")\n",
    "\n",
    "gt_mapping = read_groundtruth(Config.gt_list_path)\n",
    "train_raw = read_train_list(Config.train_list_path)\n",
    "test_raw  = read_test_list(Config.test_list_path)\n",
    "\n",
    "print(f\"Line counts -> train={len(train_raw)}, test={len(test_raw)}, groundtruth={len(gt_mapping)}\")\n",
    "\n",
    "# Build raw samples with original labels\n",
    "train_samples_raw = []\n",
    "val_samples_raw   = []\n",
    "unmatched = 0\n",
    "\n",
    "# Train: labels come directly from train.txt\n",
    "for rel_path, label in train_raw:\n",
    "    full_path = Config.data_root / rel_path\n",
    "    train_samples_raw.append((full_path, label))\n",
    "\n",
    "# Val/Test: prefer label in test.txt, otherwise use groundtruth.txt\n",
    "for rel_path, label in test_raw:\n",
    "    if label is None:\n",
    "        label = gt_mapping.get(rel_path, None)\n",
    "    if label is None:\n",
    "        unmatched += 1\n",
    "        continue\n",
    "    full_path = Config.data_root / rel_path\n",
    "    val_samples_raw.append((full_path, label))\n",
    "\n",
    "all_labels_raw = [lbl for _, lbl in train_samples_raw] + [lbl for _, lbl in val_samples_raw]\n",
    "unique_labels = sorted(set(all_labels_raw))\n",
    "\n",
    "# Map original labels -> contiguous [0, num_classes-1]\n",
    "label_to_idx = {lab: idx for idx, lab in enumerate(unique_labels)}\n",
    "idx_to_label = {idx: lab for lab, idx in label_to_idx.items()}\n",
    "\n",
    "# Apply mapping\n",
    "train_samples = [(path, label_to_idx[lbl]) for path, lbl in train_samples_raw]\n",
    "val_samples   = [(path, label_to_idx[lbl]) for path, lbl in val_samples_raw]\n",
    "\n",
    "Config.num_classes = len(unique_labels)\n",
    "\n",
    "print(f\"[Info] Original label min={min(all_labels_raw)}, max={max(all_labels_raw)}\")\n",
    "print(f\"[Info] Number of unique labels={Config.num_classes}\")\n",
    "print(f\"[Info] Train samples: {len(train_samples)}, Val samples: {len(val_samples)}, Unmatched test: {unmatched}\")\n",
    "print(f\"[Info] Labels have been remapped to range [0, {Config.num_classes - 1}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a681b8c",
   "metadata": {},
   "source": [
    "# 6. Dataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4566864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 297, Val batches: 13\n"
     ]
    }
   ],
   "source": [
    "class PlantsDataset(Dataset):\n",
    "    def __init__(self, samples, train: bool = True):\n",
    "        \"\"\"\n",
    "        samples: list of (full_path: Path, label_idx: int)\n",
    "        train : True 表示训练集（会根据 USE_AUG 决定要不要 augmentation）\n",
    "                False 表示验证/测试集（永远不用 augmentation）\n",
    "        \"\"\"\n",
    "        self.samples = samples\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # 根据路径和 train / val 选择对应的 transform\n",
    "        # pick_transform 在前面已经定义好了：\n",
    "        #   def pick_transform(rel_path: str, train: bool = True): ...\n",
    "        rel_path = str(img_path)\n",
    "        transform = pick_transform(rel_path, train=self.train)\n",
    "\n",
    "        img = transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# === Datasets ===\n",
    "train_dataset = PlantsDataset(train_samples, train=True)\n",
    "val_dataset   = PlantsDataset(val_samples,   train=False)\n",
    "\n",
    "# === Dataloaders ===\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=Config.num_workers,\n",
    "    pin_memory=Config.pin_memory,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.num_workers,\n",
    "    pin_memory=Config.pin_memory,\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6971de",
   "metadata": {},
   "source": [
    "# 7. MAE Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e55489df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAEForPlants(\n",
      "  (backbone): ViTMAEModel(\n",
      "    (embeddings): ViTMAEEmbeddings(\n",
      "      (patch_embeddings): ViTMAEPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "    )\n",
      "    (encoder): ViTMAEEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x ViTMAELayer(\n",
      "          (attention): ViTMAEAttention(\n",
      "            (attention): ViTMAESelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (output): ViTMAESelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTMAEIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTMAEOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (production): Sequential(\n",
      "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MAEForPlants(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = ViTMAEModel.from_pretrained(model_name)\n",
    "        embed_dim = self.backbone.config.hidden_size\n",
    "\n",
    "        self.production = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),       # 你可以保持 0.1 或改 0.2 都可以\n",
    "        )\n",
    "        # 如果你之前加了第二个 dropout 也可以保留\n",
    "        # self.dropout2 = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(pixel_values=x)\n",
    "        cls_token = out.last_hidden_state[:, 0]\n",
    "        feats = self.production(cls_token)\n",
    "        # feats = self.dropout2(feats)  # 如果你有第二个 dropout\n",
    "        logits = self.classifier(feats)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "model = MAEForPlants(Config.model_name, Config.num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4abc2",
   "metadata": {},
   "source": [
    "# 7. Loss / Optimizer / Scheduler / AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71d0ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11484\\3771019482.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "head_params = list(model.production.parameters()) + list(model.classifier.parameters())\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),         # ⭐ 重点：整支 model 都参与训练\n",
    "    lr=Config.lr,               # 建议：比 freeze 版本稍微小一点，例如 5e-5 或 1e-5\n",
    "    weight_decay=Config.weight_decay\n",
    ")\n",
    "\n",
    "total_steps = max(1, len(train_loader)) * Config.epochs\n",
    "warmup_steps = int(Config.warmup_ratio * total_steps)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d38b7",
   "metadata": {},
   "source": [
    "# 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24bae48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training log will be saved to: runs_mae_large_AUG_5e-5\\logs\\training_log.txt\n",
      "[INFO] Best model will be saved to: runs_mae_large_AUG_5e-5\\models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:   0%|          | 0/297 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|██████████| 297/297 [19:24<00:00,  3.92s/it, acc=2.02, loss=4.58]\n",
      "Epoch 1 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.72it/s, acc=4.83, loss=4.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Acc=2.02%, Val Acc=4.83%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|██████████| 297/297 [19:56<00:00,  4.03s/it, acc=11.7, loss=3.98]\n",
      "Epoch 2 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, acc=13, loss=4.07]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Acc=11.70%, Val Acc=13.04%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|██████████| 297/297 [19:56<00:00,  4.03s/it, acc=22.5, loss=3.25]\n",
      "Epoch 3 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, acc=21.7, loss=3.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Acc=22.47%, Val Acc=21.74%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|██████████| 297/297 [20:00<00:00,  4.04s/it, acc=31.9, loss=2.7] \n",
      "Epoch 4 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, acc=33.3, loss=3.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Acc=31.89%, Val Acc=33.33%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|██████████| 297/297 [20:18<00:00,  4.10s/it, acc=41.2, loss=2.31]\n",
      "Epoch 5 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.71it/s, acc=39.6, loss=2.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Acc=41.19%, Val Acc=39.61%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Train]: 100%|██████████| 297/297 [20:17<00:00,  4.10s/it, acc=47.8, loss=1.99]\n",
      "Epoch 6 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, acc=41.5, loss=2.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Acc=47.81%, Val Acc=41.55%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Train]: 100%|██████████| 297/297 [20:18<00:00,  4.10s/it, acc=53.3, loss=1.77]\n",
      "Epoch 7 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.67it/s, acc=45.4, loss=2.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Acc=53.27%, Val Acc=45.41%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [Train]: 100%|██████████| 297/297 [20:45<00:00,  4.19s/it, acc=56.8, loss=1.57]\n",
      "Epoch 8 [Val]: 100%|██████████| 13/13 [00:09<00:00,  1.40it/s, acc=49.3, loss=2.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Acc=56.77%, Val Acc=49.28%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Train]: 100%|██████████| 297/297 [20:33<00:00,  4.15s/it, acc=63, loss=1.4]   \n",
      "Epoch 9 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.71it/s, acc=48.8, loss=2.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Acc=62.96%, Val Acc=48.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Train]: 100%|██████████| 297/297 [20:15<00:00,  4.09s/it, acc=64.8, loss=1.28]\n",
      "Epoch 10 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.70it/s, acc=50.2, loss=2.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Acc=64.84%, Val Acc=50.24%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [Train]: 100%|██████████| 297/297 [20:17<00:00,  4.10s/it, acc=67.4, loss=1.18]\n",
      "Epoch 11 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.71it/s, acc=54.1, loss=2.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Acc=67.37%, Val Acc=54.11%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [Train]: 100%|██████████| 297/297 [20:19<00:00,  4.11s/it, acc=70.4, loss=1.07]\n",
      "Epoch 12 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.69it/s, acc=56, loss=2.57]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Acc=70.45%, Val Acc=56.04%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [Train]: 100%|██████████| 297/297 [20:16<00:00,  4.10s/it, acc=74.2, loss=0.92] \n",
      "Epoch 13 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.72it/s, acc=54.6, loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Acc=74.22%, Val Acc=54.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [Train]: 100%|██████████| 297/297 [20:15<00:00,  4.09s/it, acc=76.9, loss=0.836]\n",
      "Epoch 14 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.72it/s, acc=56, loss=2.58]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Acc=76.94%, Val Acc=56.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [Train]: 100%|██████████| 297/297 [20:16<00:00,  4.10s/it, acc=78.3, loss=0.767]\n",
      "Epoch 15 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.70it/s, acc=56, loss=2.56]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Acc=78.29%, Val Acc=56.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [Train]: 100%|██████████| 297/297 [20:28<00:00,  4.14s/it, acc=79.4, loss=0.705]\n",
      "Epoch 16 [Val]: 100%|██████████| 13/13 [00:09<00:00,  1.42it/s, acc=56.5, loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Acc=79.41%, Val Acc=56.52%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [Train]: 100%|██████████| 297/297 [20:59<00:00,  4.24s/it, acc=82.1, loss=0.636]\n",
      "Epoch 17 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.68it/s, acc=58.5, loss=2.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Acc=82.12%, Val Acc=58.45%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [Train]: 100%|██████████| 297/297 [20:23<00:00,  4.12s/it, acc=83.9, loss=0.557]\n",
      "Epoch 18 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.69it/s, acc=54.1, loss=2.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Acc=83.92%, Val Acc=54.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 [Train]: 100%|██████████| 297/297 [20:20<00:00,  4.11s/it, acc=85.6, loss=0.508]\n",
      "Epoch 19 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.74it/s, acc=58.5, loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Acc=85.60%, Val Acc=58.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 [Train]: 100%|██████████| 297/297 [20:20<00:00,  4.11s/it, acc=87.2, loss=0.456]\n",
      "Epoch 20 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.69it/s, acc=58, loss=2.52]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Acc=87.23%, Val Acc=57.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 [Train]: 100%|██████████| 297/297 [20:19<00:00,  4.11s/it, acc=88.5, loss=0.415]\n",
      "Epoch 21 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.72it/s, acc=59.4, loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train Acc=88.53%, Val Acc=59.42%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 [Train]: 100%|██████████| 297/297 [20:06<00:00,  4.06s/it, acc=89.8, loss=0.382]\n",
      "Epoch 22 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.71it/s, acc=58.5, loss=2.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train Acc=89.84%, Val Acc=58.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 [Train]: 100%|██████████| 297/297 [19:56<00:00,  4.03s/it, acc=90.3, loss=0.348]\n",
      "Epoch 23 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.83it/s, acc=56.5, loss=2.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train Acc=90.32%, Val Acc=56.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 [Train]: 100%|██████████| 297/297 [19:50<00:00,  4.01s/it, acc=91.7, loss=0.305]\n",
      "Epoch 24 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.82it/s, acc=59.4, loss=2.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train Acc=91.69%, Val Acc=59.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 [Train]: 100%|██████████| 297/297 [19:49<00:00,  4.01s/it, acc=91.5, loss=0.314]\n",
      "Epoch 25 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.84it/s, acc=59.4, loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Train Acc=91.48%, Val Acc=59.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 [Train]: 100%|██████████| 297/297 [19:50<00:00,  4.01s/it, acc=92.5, loss=0.296]\n",
      "Epoch 26 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, acc=59.9, loss=2.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Train Acc=92.54%, Val Acc=59.90%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 [Train]: 100%|██████████| 297/297 [19:51<00:00,  4.01s/it, acc=92.6, loss=0.275]\n",
      "Epoch 27 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.81it/s, acc=61.4, loss=2.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Train Acc=92.60%, Val Acc=61.35%\n",
      "[INFO] Saved BEST model to: runs_mae_large_AUG_5e-5\\models\\mae_frozen_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 [Train]: 100%|██████████| 297/297 [19:50<00:00,  4.01s/it, acc=93, loss=0.265]  \n",
      "Epoch 28 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, acc=58.9, loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Train Acc=93.04%, Val Acc=58.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 [Train]: 100%|██████████| 297/297 [19:52<00:00,  4.02s/it, acc=93.5, loss=0.255]\n",
      "Epoch 29 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.76it/s, acc=60.4, loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Train Acc=93.47%, Val Acc=60.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 [Train]: 100%|██████████| 297/297 [19:57<00:00,  4.03s/it, acc=93.1, loss=0.265]\n",
      "Epoch 30 [Val]: 100%|██████████| 13/13 [00:07<00:00,  1.80it/s, acc=59.4, loss=2.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Train Acc=93.09%, Val Acc=59.42%\n",
      "[✓] Training completed. Logs saved to runs_mae_large_AUG_5e-5\\logs\\training_log.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log_dir = Config.out_dir / \"logs\"\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# models 目录（只存 best model）\n",
    "models_dir = Config.out_dir / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log_path = log_dir / \"training_log.txt\"\n",
    "log_f = open(log_path, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[INFO] Training log will be saved to: {log_path}\")\n",
    "print(f\"[INFO] Best model will be saved to: {models_dir}\")\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\", enabled=device.type == \"cuda\"):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        pbar.set_postfix(loss=running_loss/total, acc=correct/total*100)\n",
    "\n",
    "    return running_loss/total, correct/total*100\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\")\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\", enabled=device.type == \"cuda\"):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        pbar.set_postfix(loss=running_loss/total, acc=correct/total*100)\n",
    "\n",
    "    return running_loss/total, correct/total*100\n",
    "\n",
    "\n",
    "best_val_acc = 0\n",
    "best_model_path = models_dir / \"mae_frozen_best.pth\"\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    train_loss, train_acc = train_one_epoch(epoch)\n",
    "    val_loss, val_acc = validate(epoch)\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Acc={train_acc:.2f}%, Val Acc={val_acc:.2f}%\")\n",
    "\n",
    "    # ===== 写 log =====\n",
    "    log_line = (\n",
    "        f\"Epoch {epoch+1}/{Config.epochs} | \"\n",
    "        f\"Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}% | \"\n",
    "        f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}% | \"\n",
    "        f\"Best Val Acc={max(best_val_acc, val_acc):.2f}%\\n\"\n",
    "    )\n",
    "    log_f.write(log_line)\n",
    "    log_f.flush()\n",
    "\n",
    "    # ===== 只保存 best model =====\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"[INFO] Saved BEST model to: {best_model_path}\")\n",
    "\n",
    "log_f.close()\n",
    "print(f\"[✓] Training completed. Logs saved to {log_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484cb08",
   "metadata": {},
   "source": [
    "# 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2878f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving evaluation results to: runs_mae_large_AUG_5e-5\\evaluation\n",
      "\n",
      "[Overall] Top-1 Accuracy: 59.42%\n",
      "[Overall] Top-5 Accuracy: 68.60%\n",
      "\n",
      "[Saved] Classification report → runs_mae_large_AUG_5e-5\\evaluation\\classification_report.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] Confusion matrix image → runs_mae_large_AUG_5e-5\\evaluation\\confusion_matrix.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] Per-class CSV → runs_mae_large_AUG_5e-5\\evaluation\\per_class_metrics.csv\n",
      "\n",
      "[✓] All evaluation results (including Top-1 & Top-5) saved successfully.\n",
      "\n",
      "[INFO] Saving with/without-pairs results to: runs_mae_large_AUG_5e-5\\evaluation\n",
      "#classes in WITH-PAIRS list   : 60\n",
      "#classes in WITHOUT-PAIRS list: 40\n",
      "\n",
      "=== WITH-PAIRS / WITHOUT-PAIRS Result on Validation Set ===\n",
      "Samples in WITH-PAIRS group   : 153\n",
      "Samples in WITHOUT-PAIRS group: 54\n",
      "\n",
      "Group: WITH PAIRS\n",
      "  Top-1 Accuracy: 80.39%\n",
      "  Top-5 Accuracy: 92.81%\n",
      "\n",
      "Group: WITHOUT PAIRS\n",
      "  Top-1 Accuracy: 0.00%\n",
      "  Top-5 Accuracy: 0.00%\n",
      "\n",
      "[Saved] With/without-pairs results → runs_mae_large_AUG_5e-5\\evaluation\\val_with_without_pairs_results.txt\n"
     ]
    }
   ],
   "source": [
    "# === Folder to save results ===\n",
    "eval_dir = Config.out_dir / \"evaluation\"\n",
    "eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"[INFO] Saving evaluation results to: {eval_dir}\")\n",
    "\n",
    "\n",
    "# === helper: top-k accuracy ===\n",
    "def topk_acc_from_topk_array(y_true_group, topk_array):\n",
    "    \"\"\"\n",
    "    y_true_group : [N]\n",
    "    topk_array   : [N, K]，每行是该样本 top-K 预测的类别 index\n",
    "    返回: 百分比 (0-100)\n",
    "    \"\"\"\n",
    "    if len(y_true_group) == 0:\n",
    "        return None\n",
    "    correct = np.any(topk_array == y_true_group[:, None], axis=1)\n",
    "    return correct.mean() * 100.0\n",
    "\n",
    "\n",
    "# === Collect predictions (Top-1 + Top-5) ===\n",
    "@torch.no_grad()\n",
    "def collect_preds(loader, k=5):\n",
    "    model.eval()\n",
    "    all_top1, all_topk, all_labels = [], [], []\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        logits = model(imgs)\n",
    "\n",
    "        top1 = torch.argmax(logits, dim=1)           # [B]\n",
    "        topk = torch.topk(logits, k=k, dim=1).indices  # [B, k]\n",
    "\n",
    "        all_top1.append(top1.cpu().numpy())\n",
    "        all_topk.append(topk.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "    y_pred_top1 = np.concatenate(all_top1)      # [N]\n",
    "    y_pred_topk = np.concatenate(all_topk)      # [N, k]\n",
    "    y_true      = np.concatenate(all_labels)    # [N]\n",
    "    return y_pred_top1, y_pred_topk, y_true\n",
    "\n",
    "\n",
    "y_pred, y_top5, y_true = collect_preds(val_loader, k=5)\n",
    "\n",
    "# === Overall Top-1 & Top-5 ===\n",
    "overall_top1 = accuracy_score(y_true, y_pred) * 100.0\n",
    "overall_top5 = topk_acc_from_topk_array(y_true, y_top5)\n",
    "\n",
    "print(f\"\\n[Overall] Top-1 Accuracy: {overall_top1:.2f}%\")\n",
    "print(f\"[Overall] Top-5 Accuracy: {overall_top5:.2f}%\\n\")\n",
    "\n",
    "\n",
    "# === 1. Save Classification Report ===\n",
    "report_str = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    digits=4,\n",
    "    target_names=[str(idx_to_label[i]) for i in range(len(idx_to_label))]\n",
    ")\n",
    "\n",
    "report_path = eval_dir / \"classification_report.txt\"\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Overall Top-1 Accuracy: {overall_top1:.4f}%\\n\")\n",
    "    f.write(f\"Overall Top-5 Accuracy: {overall_top5:.4f}%\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(report_str)\n",
    "\n",
    "print(f\"[Saved] Classification report → {report_path}\")\n",
    "\n",
    "\n",
    "# === 2. Save Confusion Matrix Plot (Top-1) ===\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(idx_to_label))))\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.imshow(cm, cmap=\"Blues\", interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix (counts)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "cm_path = eval_dir / \"confusion_matrix.png\"\n",
    "plt.savefig(cm_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"[Saved] Confusion matrix image → {cm_path}\")\n",
    "\n",
    "\n",
    "# === 3. Save Per-Class Metrics as CSV (from Top-1) ===\n",
    "report_dict = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    digits=4,\n",
    "    target_names=[str(idx_to_label[i]) for i in range(len(idx_to_label))],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "metrics_df = pd.DataFrame(report_dict).transpose()\n",
    "metrics_path = eval_dir / \"per_class_metrics.csv\"\n",
    "metrics_df.to_csv(metrics_path, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[Saved] Per-class CSV → {metrics_path}\")\n",
    "\n",
    "print(\"\\n[✓] All evaluation results (including Top-1 & Top-5) saved successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "# ====== Step 9 (extra): WITH / WITHOUT PAIRS 分组分析并保存到 evaluation 文件夹 ======\n",
    "\n",
    "# 0. 确保 evaluation 目录存在（和前面 Step 9 保存 report 的目录一致）\n",
    "eval_dir = Config.out_dir / \"evaluation\"\n",
    "eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\n[INFO] Saving with/without-pairs results to: {eval_dir}\")\n",
    "\n",
    "# 1. 设置 with / without pairs 的 class list 文件路径\n",
    "#    确保这两个文件在当前工作目录下，或者改成你的完整路径\n",
    "WITH_PAIRS_FILE = list_dir / \"class_with_pairs.txt\"\n",
    "WITHOUT_PAIRS_FILE = list_dir / \"class_without_pairs.txt\"\n",
    "\n",
    "# 2. 读入原始 class ID（每行一个）\n",
    "with open(WITH_PAIRS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    with_pairs_ids = {line.strip() for line in f if line.strip()}\n",
    "\n",
    "with open(WITHOUT_PAIRS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    without_pairs_ids = {line.strip() for line in f if line.strip()}\n",
    "\n",
    "print(f\"#classes in WITH-PAIRS list   : {len(with_pairs_ids)}\")\n",
    "print(f\"#classes in WITHOUT-PAIRS list: {len(without_pairs_ids)}\")\n",
    "\n",
    "# 3. 把 y_true 里的「类别 index」转换成「原始 class ID 字符串」\n",
    "#    假设 idx_to_label[i] 就是原始 ID（数字或字符串），统一转成 str 来对比\n",
    "y_true_class_ids = np.array([str(idx_to_label[int(c)]) for c in y_true])\n",
    "\n",
    "# 4. 根据 class ID mask 出 with-pair / without-pair 的样本\n",
    "mask_with_pairs = np.isin(y_true_class_ids, list(with_pairs_ids))\n",
    "mask_without_pairs = np.isin(y_true_class_ids, list(without_pairs_ids))\n",
    "\n",
    "y_true_with = y_true[mask_with_pairs]\n",
    "y_pred_with = y_pred[mask_with_pairs]\n",
    "y_top5_with = y_top5[mask_with_pairs]\n",
    "\n",
    "y_true_without = y_true[mask_without_pairs]\n",
    "y_pred_without = y_pred[mask_without_pairs]\n",
    "y_top5_without = y_top5[mask_without_pairs]\n",
    "\n",
    "print(\"\\n=== WITH-PAIRS / WITHOUT-PAIRS Result on Validation Set ===\")\n",
    "print(f\"Samples in WITH-PAIRS group   : {len(y_true_with)}\")\n",
    "print(f\"Samples in WITHOUT-PAIRS group: {len(y_true_without)}\")\n",
    "\n",
    "# 防止某个 group 为空\n",
    "if len(y_true_with) > 0:\n",
    "    acc_with_top1 = accuracy_score(y_true_with, y_pred_with) * 100.0\n",
    "    acc_with_top5 = topk_acc_from_topk_array(y_true_with, y_top5_with)\n",
    "    print(f\"\\nGroup: WITH PAIRS\")\n",
    "    print(f\"  Top-1 Accuracy: {acc_with_top1:.2f}%\")\n",
    "    print(f\"  Top-5 Accuracy: {acc_with_top5:.2f}%\")\n",
    "else:\n",
    "    acc_with_top1 = None\n",
    "    acc_with_top5 = None\n",
    "    print(\"\\nGroup: WITH PAIRS\")\n",
    "    print(\"  (No samples from WITH-PAIRS class IDs found in this validation set.)\")\n",
    "\n",
    "if len(y_true_without) > 0:\n",
    "    acc_without_top1 = accuracy_score(y_true_without, y_pred_without) * 100.0\n",
    "    acc_without_top5 = topk_acc_from_topk_array(y_true_without, y_top5_without)\n",
    "    print(f\"\\nGroup: WITHOUT PAIRS\")\n",
    "    print(f\"  Top-1 Accuracy: {acc_without_top1:.2f}%\")\n",
    "    print(f\"  Top-5 Accuracy: {acc_without_top5:.2f}%\")\n",
    "else:\n",
    "    acc_without_top1 = None\n",
    "    acc_without_top5 = None\n",
    "    print(\"\\nGroup: WITHOUT PAIRS\")\n",
    "    print(\"  (No samples from WITHOUT-PAIRS class IDs found in this validation set.)\")\n",
    "\n",
    "# 5. 把 with / without 的结果也存到当前 run 的 evaluation 目录里\n",
    "out_path = eval_dir / \"val_with_without_pairs_results.txt\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"WITH-PAIRS / WITHOUT-PAIRS Result on Validation Set\\n\")\n",
    "    f.write(f\"Samples in WITH-PAIRS group   : {len(y_true_with)}\\n\")\n",
    "    f.write(f\"Samples in WITHOUT-PAIRS group: {len(y_true_without)}\\n\\n\")\n",
    "\n",
    "    if acc_with_top1 is not None:\n",
    "        f.write(f\"WITH PAIRS Top-1 Accuracy   : {acc_with_top1:.4f}%\\n\")\n",
    "        f.write(f\"WITH PAIRS Top-5 Accuracy   : {acc_with_top5:.4f}%\\n\")\n",
    "    else:\n",
    "        f.write(\"WITH PAIRS: no samples in this val set\\n\")\n",
    "\n",
    "    if acc_without_top1 is not None:\n",
    "        f.write(f\"WITHOUT PAIRS Top-1 Accuracy: {acc_without_top1:.4f}%\\n\")\n",
    "        f.write(f\"WITHOUT PAIRS Top-5 Accuracy: {acc_without_top5:.4f}%\\n\")\n",
    "    else:\n",
    "        f.write(\"WITHOUT PAIRS: no samples in this val set\\n\")\n",
    "\n",
    "print(f\"\\n[Saved] With/without-pairs results → {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
